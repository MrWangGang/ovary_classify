# 因数据集涉及到隐私,github不允许上传超过100mb的文件所以模型的权重以及数据集在此仓库中不提供,如需要请联系 userbean@outlook.com - wanggang
# 卵巢癌多模态分类模型对比研究
## 项目背景
卵巢癌是女性生殖系统常见的恶性肿瘤之一，早期准确诊断对提高患者生存率和治疗效果至关重要。医学影像技术（如CT和超声）是卵巢癌诊断的重要手段，本项目通过构建多种单一模态和多模态融合模型，旨在探索最优的卵巢癌分类方案。
<img width="1640" height="966" alt="image" src="https://github.com/user-attachments/assets/ee27dd92-4253-471c-8c16-a90ef609d260" />
<img width="1588" height="1274" alt="image" src="https://github.com/user-attachments/assets/8f8f0cad-13ea-4f80-b176-440526383d79" />
<img width="1644" height="1122" alt="image" src="https://github.com/user-attachments/assets/a3e9c234-7f4c-4ee8-a9ab-f70bd0b61f2a" />

## 数据集信息
- **数据类型**：包含两种医学影像模态
  - 卵巢CT断层扫描切片
  - 卵巢超声图像
- **任务目标**：基于影像特征进行卵巢癌的二元分类（良性/恶性）

## 模型架构
为进行系统性对比实验，本项目构建了5种模型：

### 1. 单一模态UNet模型
- **CT的UNet模型**：以CT切片为输入，通过UNet架构提取空间特征并完成分类
- **超声的UNet模型**：以超声图像为输入，基于UNet架构实现特征提取与分类

### 2. 单一模态ResNet模型
- **CT的ResNet模型**：采用ResNet作为骨干网络，专注处理CT影像数据
- **超声的ResNet模型**：基于ResNet架构，专门针对超声图像进行分类

### 3. 多模态融合模型
- **CT+超声融合ResNet模型**：创新性地结合CT和超声两种模态数据，通过特征融合策略实现联合分类，充分利用不同模态的互补信息

## 实验设计
本项目的核心是通过对比实验评估不同模型的性能，主要研究目标包括：
- 比较UNet与ResNet在相同模态下的分类效果
- 分析CT和超声两种模态各自在卵巢癌分类中的价值
- 验证多模态融合是否能显著提升分类准确率
- 确定卵巢癌影像诊断的最优模型架构

## 评估指标
为全面评估模型性能，采用以下指标：
- 准确率（Accuracy）
- 精确率（Precision）
- 召回率（Recall/Sensitivity）
- F1分数（F1-Score）
- AUC-ROC曲线及面积
- 混淆矩阵

## 预期成果
通过系统的对比分析，本研究期望：
- 明确不同模态数据在卵巢癌分类中的相对优势
- 验证多模态融合策略的有效性
- 为临床卵巢癌的影像辅助诊断提供可靠的模型支持

